{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ee38d6",
   "metadata": {},
   "source": [
    "### import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dcd3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mrmr import mrmr_classif\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import (\n",
    "    GroupKFold, GridSearchCV,\n",
    "    KFold, \n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold, \n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f305a47",
   "metadata": {},
   "source": [
    "### setup csv file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b019b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(__name__).resolve().parent.parent\n",
    "BASE_FILE_PATH = BASE_DIR / 'tabular-playground-series-nov-2022'\n",
    "SUBMISSION_FILES_PATH = BASE_FILE_PATH / 'submission_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fead08",
   "metadata": {},
   "source": [
    "### code transcription(TPS Nov 2022 | EDA + Hybrid Stacking ğŸš€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "755cac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED\n",
    "\n",
    "seed = 2484\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a2c3c",
   "metadata": {},
   "source": [
    "#### Files\n",
    "- submission_files/ - a folder containing binary model predictions\n",
    "- train_labels.csv - the ground truth labels for the first half of the rows in the submission files\n",
    "- sample_submission.csv - a sample submission file in the correct format, only containing the row ids for the second - - half of each file in the submissions folder; your task is to blend together submissions that achieve the improvements in the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb4e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(BASE_FILE_PATH / 'sample_submission.csv', index_col='id')\n",
    "\n",
    "labels = pd.read_csv(BASE_FILE_PATH / 'train_labels.csv', index_col='id')\n",
    "\n",
    "# the ids of the submission rows (useful later)\n",
    "sub_ids = submission.index\n",
    "\n",
    "# the ids of the labeled rows (useful later)\n",
    "gt_ids = labels.index \n",
    "\n",
    "# list of files in the submission folder\n",
    "subs = sorted(os.listdir(SUBMISSION_FILES_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5b4e1",
   "metadata": {},
   "source": [
    "#### Labels distribution\n",
    "The ground truth for these rows are provided in the file train_labels.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd115ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b160912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize = (15, 7))\n",
    "labels_names = [f\"{p:.2f}%\" for p in labels.value_counts() / labels.value_counts().sum() * 100]\n",
    "labels.value_counts().plot(kind='pie', ax=ax[0], labels=labels_names, colors=(\"r\", \"b\"), ylabel=\"label\")\n",
    "labels.value_counts().plot(kind='bar', ax=ax[1], color=(\"r\", \"b\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c377319",
   "metadata": {},
   "source": [
    "#### Submissions files\n",
    "Each file name in the submissions folder corresponds to the logloss score of the the first half of the prediction rows (20k rows) against the ground truth labels in that file. This is effectively the \"training\" set.\n",
    "\n",
    "(íŠ¸ë ˆì´ë‹ ì„¸íŠ¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f036d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = pd.read_csv(SUBMISSION_FILES_PATH / subs[0], index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d13e57bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6222863195.csv  log_loss: 0.6222863195\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "log_loss \n",
    "ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ì§€í‘œ\n",
    "ë¶„ë¥˜(Classification) ëª¨ë¸ í‰ê°€ì‹œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "ê°’ì´ ì‘ì„ìˆ˜ë¡ ì¢‹ì€ ëª¨ë¸\n",
    "'''\n",
    "\n",
    "score = log_loss(labels, s0.loc[gt_ids])\n",
    "\n",
    "# Notice the score of the labeled rows matches the file name\n",
    "print(subs[0],' log_loss:', f'{score:.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f01629d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eb7e10",
   "metadata": {},
   "source": [
    "#### Loading all submission files\n",
    "we are going to load all submission files into a dataframe with final shape 40k x 5k. Each Submission file will go into a column of the dataframe\n",
    "\n",
    "We also calculate the ROC-AUC for each submission file in order to use this metric later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c392462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [06:09, 13.54it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_orig = np.zeros((s0.shape[0], len(subs))) # (5000, 40000)\n",
    "roc_auc_scores = dict()\n",
    "\n",
    "for i, name in tqdm(enumerate(subs)):\n",
    "    \n",
    "    # submission_filesì— íŒŒì¼ë“¤ì„ í•˜ë‚˜ì”© ì½ì–´ì™€ì„œ X_train_origì— ì²«ë²ˆì§¸ rowì— ì €ì¥\n",
    "    sub = pd.read_csv(SUBMISSION_FILES_PATH / name, index_col='id')\n",
    "    X_train_orig[:, i] = sub.pred.values\n",
    "    \n",
    "    # roc_auc_score ì •í™•ë„ í‰ê°€\n",
    "    # ROC Curveì˜ ë©´ì , AUCì˜ ê°’ì´ 1ì¼ ìˆ˜ë¡ ì¢‹ì€ ëª¨ë¸ì´ë¼ í‰ê°€\n",
    "    # (ì‹¤ì œ ì •ë‹µ ë¦¬ìŠ¤íŠ¸(ì •ìˆ˜), 1ì¼ í™•ë¥ ì´ ë‹´ê¸´ ë¦¬ìŠ¤íŠ¸(ì‹¤ìˆ˜)) ì´ë ‡ê²Œ ì—°ì‚°í•œ ê²°ê³¼ê°€ 1ì— ê°€ê¹Œìš¸ ì •ë„ë¡œ ë†’ì€ ìˆ˜ì¹˜ê°€ ë‚˜ì˜´\n",
    "    # labels.label 20kê°œ, X_train_origì—ì„œ i columnsì˜ 0~20kê¹Œì§€ì˜ row ê°’\n",
    "    auc_score = roc_auc_score(labels.label[0:20000], X_train_orig[0:20000, i])\n",
    "    \n",
    "    # ì—°ì‚°ëœ ìˆ˜ì¹˜ê°’ì„ roc_auc_scoresì— ì €ì¥\n",
    "    roc_auc_scores[name] = auc_score\n",
    "    \n",
    "# X_train_origìœ¼ë¡œ ë§Œë“¤ì–´ì§„ array?ë¡œ DataFrame ìƒì„±\n",
    "X_train_orig = pd.DataFrame(X_train_orig, columns=subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ba8c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab690f2",
   "metadata": {},
   "source": [
    "#### Removing Strange submission files\n",
    "we are going to remove strange submission files with values >1 or <0 As result we remove 108 submission files\n",
    "\n",
    "Instead of removing strange submission files we try to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa48476",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train_orig = X_train_orig.loc[:, X_train_orig.max()<=1]\n",
    "X_train_orig = X_train_orig.loc[:, X_train_orig.min()>=0]\n",
    "\n",
    "numpy.clip(array, min, max)\n",
    "array ë‚´ì˜ elementë“¤ì— ëŒ€í•´ì„œ\n",
    "min ê°’ ë³´ë‹¤ ì‘ì€ ê°’ë“¤ì„ minê°’ìœ¼ë¡œ ë°”ê¿”ì£¼ê³ \n",
    "max ê°’ ë³´ë‹¤ í° ê°’ë“¤ì„ maxê°’ìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜.\n",
    "'''\n",
    "\n",
    "X_train_orig = X_train_orig.clip(0, 1)\n",
    "\n",
    "# 2 variables removed since they were low-information variables\n",
    "# 0.6933054832.csv, 0.6933472206.csv cloumns ê°’ì´ ì „ë¶€ ë™ì¼\n",
    "DROP_LOW_INFO_FEATURES = ['0.6933054832.csv', '0.6933472206.csv']\n",
    "\n",
    "# ì œê±°í›„ X_train_origì— ì ìš© \n",
    "X_train_orig = X_train_orig[list(set(X_train_orig.columns) - set(DROP_LOW_INFO_FEATURES))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f14d6b",
   "metadata": {},
   "source": [
    "#### Calibration of Train set (Train set ë³´ì •)\n",
    "Our train set is composed of several models' predictions output, so it's a good idea to calibrate their output before training a blended model with these  \n",
    "(í˜„ì¬ Train setëŠ” ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ í˜¼í•© ëª¨ë¸ì„ training ì „ ë³´ì •ì´ í•„ìš”)\n",
    "\n",
    "ref. https://www.kaggle.com/competitions/tabular-playground-series-nov-2022/discussion/363778"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaacdb76",
   "metadata": {},
   "source": [
    "##### sklearn CalibrationDisplay\n",
    "\n",
    "êµì • ê³¡ì„ (ì‹ ë¢°ë„ ë‹¤ì´ì–´ê·¸ë¨ì´ë¼ê³ ë„ í•¨) ì‹œê°í™”\n",
    "ì‹¤ì œ ë ˆì´ë¸”ê³¼ ì˜ˆì¸¡ í™•ë¥ ì„ ì‚¬ìš©í•˜ì—¬ ë³´ì •(êµì¡) ê³¡ì„ ì„ ê·¸ë¦½ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "**Methods**\n",
    "\n",
    "**from_estimator(estimator, X, y, *[, n_bins, ...]):** Plot calibration curve using a binary classifier and data.\n",
    "\n",
    "**from_predictions(y_true, y_prob, *[, ...]):** Plot calibration curve using true labels and predicted probabilities.\n",
    "\n",
    "**plot(*[, ax, name, ref_line]):** Plot visualization.\n",
    "\n",
    "---\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "\n",
    "**'X':** {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "    Input values.\n",
    "    \n",
    "**'y':** array-like of shape (n_samples,)\n",
    "    Binary target values.\n",
    "    \n",
    "**'n_bins':** int, default=5\n",
    "    Number of bins to discretize the [0, 1] interval into when calculating the calibration curve. \n",
    "    A bigger number requires more data.\n",
    "    \n",
    "**'strategy':** {â€˜uniformâ€™, â€˜quantileâ€™}, default=â€™uniformâ€™\n",
    "    Strategy used to define the widths of the bins.\n",
    "    \n",
    "    - 'uniform': The bins have identical widths.\n",
    "    - 'quantile': The bins have the same number of samples and depend on predicted probabilities.\n",
    "        \n",
    "**'pos_label':** str or int, default=None\n",
    "    The positive class when computing the calibration curve. \n",
    "    By default, estimators.classes_[1] is considered as the positive class.\n",
    "    \n",
    "**'name':** str, default=None\n",
    "    Name for labeling curve. If None, the name of the estimator is used.\n",
    "    \n",
    "**'ref_line':** bool, default=True\n",
    "    If True, plots a reference line representing a perfectly calibrated classifier.\n",
    "    \n",
    "**'ax':** matplotlib axes, default=None\n",
    "    Axes object to plot on. If None, a new figure and axes is created.\n",
    "    \n",
    "---\n",
    "\n",
    "ref: https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibrationDisplay.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "298aa99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of an uncalibrated model prediction on train set\n",
    "\n",
    "X_train_orig[:20000]['0.6222863195.csv']\n",
    "X_train_orig[:]['0.6223807245.csv'].plot(kind='hist', bins=100)\n",
    "    \n",
    "CalibrationDisplay.from_predictions(\n",
    "    labels.label[0:20000], \n",
    "    X_train_orig[0:20000]['0.6223807245.csv'], \n",
    "    n_bins=20,\n",
    "    strategy='quantile', \n",
    "    color='#ffd700')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af9e036",
   "metadata": {},
   "source": [
    "##### sklearn sotonicRegression ë“±íšŒê·€\n",
    "\n",
    "â–  ë“±íšŒê·€ëŠ” ì–¸ì œ ì‚¬ìš©ë˜ë‚˜?\n",
    "ë“±íšŒê·€ëŠ” í†µê³„ì  ì¶”ë¡ ì— ì‚¬ìš©ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´, xì˜ ìˆœì„œì— ë”°ë¼ yê°’ì´ ì¦ê°€í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ë°ì´í„° ì…‹ì˜ ê²½ìš°, ë“±íšŒê·€ì‹ì„ ì ìš©í•  ìˆ˜ ìˆë‹¤. \n",
    "ë¶„ë¥˜(classification) ë¬¸ì œì—ì„œëŠ” ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì„ ë³´ì •(calibration)í•  ë•Œë„ ì‚¬ìš©ëœë‹¤. \n",
    "\n",
    "---\n",
    "\n",
    "**Methods**\n",
    "\n",
    "**fit(X, y[, sample_weight]):** Fit the model using X, y as training data.\n",
    "\n",
    "**fit_transform(X[, y]):** Fit to data, then transform it.\n",
    "\n",
    "**get_feature_names_out([input_features]):** Get output feature names for transformation.\n",
    "\n",
    "**get_params([deep]):** Get parameters for this estimator.\n",
    "\n",
    "**predict(T):** Predict new data by linear interpolation.\n",
    "\n",
    "**score(X, y[, sample_weight]):** Return the coefficient of determination of the prediction.\n",
    "\n",
    "**set_params(**params):** Set the parameters of this estimator.\n",
    "\n",
    "**transform(T):** Transform new data by linear interpolation.\n",
    "\n",
    "---\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "**y_minfloat, default=None:**\n",
    "Lower bound on the lowest predicted value (the minimum value may still be higher). If not set, defaults to -inf.\n",
    "\n",
    "**y_maxfloat, default=None:**\n",
    "Upper bound on the highest predicted value (the maximum may still be lower). If not set, defaults to +inf.\n",
    "\n",
    "**increasingbool or â€˜autoâ€™, default=True:**\n",
    "Determines whether the predictions should be constrained to increase or decrease with X. â€˜autoâ€™ will decide based on the Spearman correlation estimateâ€™s sign.\n",
    "\n",
    "**out_of_bounds{â€˜nanâ€™, â€˜clipâ€™, â€˜raiseâ€™}, default=â€™nanâ€™:**\n",
    "Handles how X values outside of the training domain are handled during prediction.\n",
    "\n",
    "- â€˜nanâ€™, predictions will be NaN.\n",
    "\n",
    "- â€˜clipâ€™, predictions will be set to the value corresponding to the nearest train interval endpoint.\n",
    "\n",
    "- â€˜raiseâ€™, a ValueError is raised.\n",
    "\n",
    "---\n",
    "\n",
    "ref: https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.IsotonicRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7f1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set calibration \n",
    "# ref. https://www.kaggle.com/competitions/tabular-playground-series-nov-2022/discussion/363778\n",
    "\n",
    "roc_auc_scores_calibrated = {}\n",
    "X_train_calibrated = X_train_orig.copy()\n",
    "\n",
    "for i, c in tqdm(enumerate(X_train_orig.columns)):\n",
    "    \n",
    "    # ê¸¸ì´ê°€ 40kì¸ list ìƒì„±\n",
    "    x_model_calibration = np.zeros(40000)\n",
    "    \n",
    "    # ë“±íšŒê·€ ëª¨ë¸ ìƒì„±\n",
    "    model_calibration = IsotonicRegression(out_of_bounds='clip')\n",
    "    \n",
    "    # train ë°ì´í„°ë¥¼ fit_transform()ì„ í•˜ì—¬ ë²”ìœ„ë¥¼ ë§ì¶”ê³  í•™ìŠµí›„? ë³€í™˜ ë° ì €ì¥ \n",
    "    # clipìœ¼ë¡œ min=0.001, max=0.999ë¡œ ë³€í™˜\n",
    "    x_model_calibration[:20000] = model_calibration.fit_transform(\n",
    "        X_train_orig[:20000][c], labels.label).clip(0.001, 0.999)\n",
    "    \n",
    "    # ë‚˜ë¨¸ì§€ ë¶€ë¶„ë„ ë³€í™˜ í›„ ì €ì¥\n",
    "    # clipìœ¼ë¡œ min=0.001, max=0.999ë¡œ ë³€í™˜\n",
    "    x_model_calibration[20000:] = model_calibration.transform(\n",
    "        X_train_orig[20000:][c]).clip(0.001, 0.999)\n",
    "    \n",
    "    # ê²°ê³¼ ê°’ X_train_calibrated dictì— ì €ì¥\n",
    "    X_train_calibrated[c] = x_model_calibration\n",
    "    \n",
    "    # roc_auc_score ì •í™•ë„ í‰ê°€\n",
    "    # ROC Curveì˜ ë©´ì , AUCì˜ ê°’ì´ 1ì¼ ìˆ˜ë¡ ì¢‹ì€ ëª¨ë¸ì´ë¼ í‰ê°€\n",
    "    auc_score = roc_auc_score(labels.label[0:20000], x_model_calibration[0:20000])\n",
    "    \n",
    "    # í‰ê°€ëœ ê°’ì„ roc_auc_scores_calibrated dictì— ì €ì¥\n",
    "    roc_auc_scores_calibrated[c] = auc_score\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    pd.DataFrame(X_train_calibrated[:20000][X_train_calibrated.columns[0]]).plot(\n",
    "        kind='hist', bins=100)\n",
    "    \n",
    "    # ì‹¤ì œ ë ˆì´ë¸”ê³¼ ì˜ˆì¸¡ í™•ë¥ ì„ ì‚¬ìš©í•˜ì—¬ ë³´ì •(êµì •) ê³¡ì„  ì‹œê°í™”.\n",
    "    CalibrationDisplay.from_predictions(\n",
    "        labels.label[0:20000], \n",
    "        X_train_calibrated[:20000][X_train_calibrated.columns[0]], \n",
    "        n_bins=20,                                \n",
    "        strategy='quantile', \n",
    "        color='#ffd700')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4771062",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(roc_auc_scores_calibrated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490bb683",
   "metadata": {},
   "source": [
    "##### Dimensionality Reduction with ROC-AUC? Why not!\n",
    "\n",
    "---\n",
    "\n",
    "##### Idea for Feature Selection using ROC-AUC\n",
    "\n",
    "A bad classifier can be identified by the ROC curve which looks very similar, if not identical, to the diagonal of the graph, representing the performance of a purely random classifier; ROC-AUC scores close to 0.5 are considered near-random results.  \n",
    "\n",
    "---\n",
    "\n",
    "Starting from the concepts behind ROC-AUC explained above, we are going to use only submissions where the ROC-AUC is major of a threshold  \n",
    "ROC-AUCê°€ ì£¼ìš” ì„ê³„ê°’ë§Œ ì‚¬ìš©í•´ì„œ ì œì¶œí•œë‹¤?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfaf2608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AUC_TH = 0.787\n",
    "fig = plt.figure(figsize=(30, 5))\n",
    "fig.suptitle(\"ROC-AUC Distribution\")\n",
    "out = plt.hist(roc_auc_scores_calibrated.values(), bins=200, color=(\"b\"))\n",
    "plt.plot([AUC_TH, AUC_TH], [0, 500], linestyle='dotted', c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65f66753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SELECTED_FEATURES = []\n",
    "TOP_LOG_LOSS_TH = 500\n",
    "\n",
    "\n",
    "for k, v in roc_auc_scores_calibrated.items():    \n",
    "    \n",
    "    # AUC_TH = 0.787\n",
    "    if v >= AUC_TH:\n",
    "        if k in X_train_orig.columns:\n",
    "            SELECTED_FEATURES.append(k)\n",
    "            \n",
    "print(len(SELECTED_FEATURES), SELECTED_FEATURES[:TOP_LOG_LOSS_TH])\n",
    "\n",
    "# X_train_calibrated (ë“±íšŒê·€ë¡œ ë³´ì •ëœ ê°’ì´ ì €ì¥ëœ dict)ì— AUC_THê°€ 0.787 ê°™ê±°ë‚˜ í° key ê°’ë§Œ ë½‘ì•„ì„œ(ìµœëŒ€ 500ê°œ) ì €ì¥\n",
    "X_train_reduced = X_train_calibrated[SELECTED_FEATURES[:TOP_LOG_LOSS_TH]]\n",
    "print(X_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50366212",
   "metadata": {},
   "source": [
    "##### Feature Selection with MRMR (optional)\n",
    "Maximum Relevance â€” Minimum Redundancyâ€ (aka MRMR) is an algorithm used by Uberâ€™s machine learning platform for finding the â€œminimal-optimalâ€ subset of features.\n",
    "\n",
    "- Enabling FEATURE_SELECTION_ENABLED the train will be done with the features selection algorithm\n",
    "- Disabling FEATURE_SELECTION_ENABLED the train will be done with all features availables in the train set (all columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b423c8",
   "metadata": {},
   "source": [
    "##### mrmr_classif\n",
    "\n",
    "---\n",
    "\n",
    "mRMRì€ filter methodì˜ í•œ ë°©ë²•ìœ¼ë¡œì¨, ë‘ ê°€ì§€ ìš”ì†Œë¥¼ ê³ ë ¤í•©ë‹ˆë‹¤. ë°”ë¡œ, Yë¥¼ ì˜ ì˜ˆì¸¡í•˜ëŠ” ë³€ìˆ˜ì´ë©´ì„œ, Xë“¤ê³¼ë„ ì¤‘ë³µì„±ì´ ì ì€ ë³€ìˆ˜ë“¤ì„ ì„ íƒí•©ë‹ˆë‹¤. ì´ ë•Œ, Yì™€ì˜ ìƒê´€ì„±ê³¼ Xë“¤ê³¼ì˜ ì¤‘ë³µì„±ì€ ì¼ë°˜ì ìœ¼ë¡œ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ì™€ Mutual informationìœ¼ë¡œ ì¸¡ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "ref: https://github.com/smazzanti/mrmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a6de21f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FEATURE_SELECTION_ENABLED = True\n",
    "# FEATURE SELECTION MRMR\n",
    "def feature_selection(X, y, k):\n",
    "    if not FEATURE_SELECTION_ENABLED:\n",
    "        return X.columns\n",
    "    \n",
    "    # mrmrë¡œ Feature Selection\n",
    "    # k ParameterëŠ” ë°›ì•„ë³¼ ê²°ê³¼ ê°¯ìˆ˜?\n",
    "    out = mrmr_classif(X, y, k)\n",
    "    print(\"Features selection:\", out)\n",
    "    return out\n",
    "\n",
    "if FEATURE_SELECTION_ENABLED:\n",
    "    FEATURES_SELECTED = feature_selection(X_train_reduced[0:20000], labels.label, 50)\n",
    "    X_train_reduced = X_train_reduced[FEATURES_SELECTED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad21bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e472562",
   "metadata": {},
   "source": [
    "###### Feature Engineering\n",
    "\n",
    "---\n",
    "\n",
    "**Adding Unsupervised new feature**\n",
    "\n",
    "we try to add an unsupervised new feature calculated with kmeans and others as combination of features and mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9825890",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced['cluster'] = KMeans(n_clusters=5, random_state=seed).fit_predict(X_train_reduced)\n",
    "X_train_reduced['mean'] = X_train_reduced.mean(axis=1)\n",
    "\n",
    "# compose a new feature as combination of two best features\n",
    "X_train_reduced['compose_feature'] = (\n",
    "    X_train_reduced['0.6778730537.csv'] + X_train_reduced['0.6702783631.csv']) / X_train_reduced['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed457a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73b763cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab373c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced['compose_feature']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3875f85",
   "metadata": {},
   "source": [
    "##### Blending/Stacking Model\n",
    "\n",
    "StratifiedKFoldì„ ì´ìš©í•œ í•™ìŠµ ë°ì´í„° ë¶„ë¥˜ (êµì°¨ê²€ì¦)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48858a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "k_fold = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=seed)\n",
    "y = labels\n",
    "X = X_train_reduced[0:20000]\n",
    "X_test = X_train_reduced[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61116382",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd5ded39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fdfd0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd038f5",
   "metadata": {},
   "source": [
    "##### RandomSearchCV\n",
    "\n",
    "To find the best hyperparameters, we will use the RandomSearchCV. Random search is a technique more faster than GridSearchCV which calculates all possible combinations\n",
    "\n",
    "RandomSearchCVë¥¼ ì´ìš©í•´ best hyperparameters ì°¾ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c61bc289",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X, y, test_size = 0.01, shuffle=True, random_state= seed, stratify=y)\n",
    "\n",
    "X_train = X_train.reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "X_validation = X_validation.reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "y_train = y_train.reset_index()['label']\n",
    "\n",
    "y_validation = y_validation.reset_index()['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ffa6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55d5de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49b1f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f588beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "057c7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'eval_metric': 'binary_logloss', \n",
    "    'eval_set': [(X_validation, y_validation)],   \n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "param_test = {\n",
    "  'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.08, 0.1, 0.2, 0.3, 0.4],\n",
    "  'n_estimators': [100, 200, 300, 400, 500, 600, 800, 1000, 1500, 2000],\n",
    "  'num_leaves': sp_randint(6, 50, 100), \n",
    "  'min_child_samples': sp_randint(100, 500), \n",
    "  'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "  'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "  'max_depth': [-1, 1, 2, 3, 4, 5, 6, 7],\n",
    "  'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "  'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "  'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa5c42fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_rs = LGBMClassifier(metric = 'binary_logloss', \n",
    "    random_state = seed, \n",
    "    silent = True, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = lgbm_rs, \n",
    "    param_distributions = param_test,     \n",
    "    scoring = 'neg_log_loss',\n",
    "    cv = k_fold,\n",
    "    refit = True,\n",
    "    random_state = seed,\n",
    "    verbose = 100, \n",
    "    n_iter = 50\n",
    ")\n",
    "\n",
    "opt_parameters = {\n",
    "    'colsample_bytree': 0.45066268483824545,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 5,\n",
    "    'min_child_samples': 285,\n",
    "    'min_child_weight': 0.01,\n",
    "    'n_estimators': 300,\n",
    "    'num_leaves': 116,\n",
    "    'reg_alpha': 1,\n",
    "    'reg_lambda': 1,\n",
    "    'subsample': 0.532329735064063\n",
    "}\n",
    "\n",
    "RS_FIT = False # enable it to use RandomSearchCV\n",
    "\n",
    "if RS_FIT:\n",
    "    random_search.fit(X, y, **fit_params)\n",
    "    opt_parameters = random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d798de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f0ce2",
   "metadata": {},
   "source": [
    "##### Hybrid Model Class\n",
    "The following class permit us to encapsulate the logic of ensembling N models making a weighted average of their predictions (Soft-Voting)\n",
    "\n",
    "We are going to choose several models in order to ensemble them and try to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfe927bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleHybrid:\n",
    "   def __init__(self, models=[], weights=[]):\n",
    "       self.models = models\n",
    "       self.weights = weights\n",
    "\n",
    "   def fit(self, X, y):\n",
    "       # Train models\n",
    "       for m in self.models:\n",
    "           print(f\"Training {m}...\")\n",
    "           m.fit(X, y)\n",
    "\n",
    "   def predict_proba(self, X_test):\n",
    "       y_pred = pd.Series(np.zeros(X_test.shape[0]), index=X_test.index)\n",
    "       for i, m in enumerate(self.models):\n",
    "           y_pred += pd.Series(m.predict_proba(X_test)[:,1], index=X_test.index) * self.weights[i]\n",
    "       return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd03f390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def folds_model(debug=True):\n",
    "    # several models in order to stacking\n",
    "    lgbm = LGBMClassifier(\n",
    "        **opt_parameters, \n",
    "        objective='binary', \n",
    "        silent=True,\n",
    "        random_state=seed,\n",
    "        metric='binary_logloss'\n",
    "    )\n",
    "    \n",
    "#     # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ë³´ì„\n",
    "#     lgbm_t = LGBMClassifier(\n",
    "#         objective='binary', \n",
    "#         silent=True,\n",
    "#         random_state=seed,\n",
    "#         metric='binary_logloss', \n",
    "#         bagging_fraction=0.5, \n",
    "#         bagging_freq=3, \n",
    "#         boosting_type='gbdt',\n",
    "#         class_weight=None, \n",
    "#         colsample_bytree=1.0, \n",
    "#         feature_fraction=0.7,\n",
    "#         importance_type='split', \n",
    "#         learning_rate=0.001, \n",
    "#         max_depth=-1,\n",
    "#         min_child_samples=6, \n",
    "#         min_child_weight=0.001, \n",
    "#         min_split_gain=0.9,\n",
    "#         n_estimators=140, \n",
    "#         n_jobs=-1, \n",
    "#         num_leaves=60, \n",
    "#         reg_alpha=0.4, \n",
    "#         reg_lambda=1e-07, \n",
    "#         subsample=1.0, \n",
    "#         subsample_for_bin=200000, \n",
    "#         subsample_freq=0\n",
    "#     )\n",
    "\n",
    "    cat_boost = CatBoostClassifier(\n",
    "        random_seed=seed,\n",
    "        eval_metric='Logloss',\n",
    "        logging_level='Silent',\n",
    "        learning_rate=0.05,\n",
    "        iterations=200\n",
    "    )\n",
    "    \n",
    "#     # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ë³´ì„\n",
    "#     cat_boost_t = CatBoostClassifier(\n",
    "#         random_seed=seed,\n",
    "#         eval_metric='Logloss',\n",
    "#         logging_level='Silent',\n",
    "#         learning_rate=0.05,\n",
    "#         iterations=200\n",
    "#     )\n",
    "\n",
    "#     # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ë³´ì„\n",
    "#     xgbm = XGBClassifier(\n",
    "#         objective='binary:logistic',\n",
    "#         random_state=seed,\n",
    "#         learning_rate=0.1,\n",
    "#         n_estimators=100,\n",
    "#         max_depth=8, \n",
    "#         #tree_method='gpu_hist'\n",
    "#     )\n",
    "    \n",
    "#     # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ë³´ì„\n",
    "#     xgbm_t = XGBClassifier(\n",
    "#         objective='binary:logistic',\n",
    "#         random_state=seed,\n",
    "#         learning_rate=0.1,\n",
    "#         n_estimators=100,\n",
    "#         max_depth=8, \n",
    "#         #tree_method='gpu_hist'\n",
    "#     )\n",
    "    \n",
    "    models = [lgbm, cat_boost]\n",
    "    weights=[0.2, 0.8]\n",
    "    Y_validations, ensemble_val_preds, ensemble_test_preds, scores = [],[],[],[]\n",
    "    \n",
    "    # Kfold.split()ìœ¼ë¡œ ë°˜í™˜ëœ ì¸ë±ìŠ¤ë¥¼ ì´ìš©, í•™ìŠµìš© ê²€ì¦ìš© ë°ì´í„° êµ¬ì„±\n",
    "    for fold, (train_idx, val_idx) in enumerate(k_fold.split(X, y)):\n",
    "        \n",
    "        if debug:\n",
    "            print(f'\\nFold {fold+1}')\n",
    "            \n",
    "        X_fold_val, Y_fold_val = X.iloc[val_idx, :], y.label[val_idx]\n",
    "        X_fold_train, Y_fold_train = X.iloc[train_idx, :], y.label[train_idx]\n",
    "        \n",
    "        if debug:\n",
    "            print(f'Train shape: {X_fold_train.shape}, {Y_fold_train.shape}, Valid shape: {X_fold_val.shape}, {Y_fold_val.shape}')\n",
    "\n",
    "        # ensemble class ìƒì„±\n",
    "        ensemble_model = EnsembleHybrid(models=models, weights=weights)\n",
    "        \n",
    "        # model fit\n",
    "        ensemble_model.fit(X_fold_train, Y_fold_train)\n",
    "        \n",
    "        # model predict\n",
    "        model_prob = ensemble_model.predict_proba(X_fold_val)        \n",
    "\n",
    "        ensemble_prob = ensemble_model.predict_proba(X_fold_val)\n",
    "        \n",
    "        Y_validations.append(Y_fold_val)\n",
    "        \n",
    "        ensemble_val_preds.append(ensemble_prob)\n",
    "        \n",
    "        ensemble_test_preds.append(ensemble_model.predict_proba(X_test))        \n",
    "\n",
    "        score = log_loss(Y_fold_val, ensemble_prob)\n",
    "        scores.append(score)\n",
    "        \n",
    "        if debug:\n",
    "            print(f'Fold {fold+1} Validation Score = {score:.4f}')\n",
    "\n",
    "        del X_fold_train, Y_fold_train, X_fold_val, Y_fold_val \n",
    "        \n",
    "    mix_score = sum(scores)/FOLDS\n",
    "    \n",
    "    if debug:\n",
    "        print('Total Score (Mixing Folds Predictions) = {:.4f}'.format(mix_score))\n",
    "        \n",
    "    return mix_score, ensemble_test_preds\n",
    "\n",
    "score, ensemble_test_preds = folds_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15c3d00d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20b9e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_blend = np.zeros(X_test.shape[0])\n",
    "\n",
    "for j in range(FOLDS):\n",
    "    folds_blend += ensemble_test_preds[j]\n",
    "    \n",
    "folds_blend = folds_blend / FOLDS\n",
    "submission['pred'] = folds_blend\n",
    "submission.to_csv('final_submission_folds_mix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17eca370",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3932bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv(BASE_DIR / 'shc/final_submission_folds_mix.csv')\n",
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
